### Project Checklist: Cirkitly v1.1

**Project Goal:** Enhance the repo-to-test pipeline to be "spec-aware." Cirkitly will read functional requirements from documentation and use them, in addition to the source code, to generate more comprehensive and targeted unit tests.

---

#### Phase 1: Project Setup & Design for Spec Integration

*   **1.1. Create a `specs` Directory:**
    *   [ ] In the root `cirkitly/` directory, create a new folder named `specs/`. This will be the conventional location for all requirement documents.

*   **1.2. Author a Sample Specification Document:**
    *   [ ] Inside `specs/`, create a new file named `spi_spec.md`.
    *   [ ] Add specific, testable requirements to this file. For example:
        ```markdown
        # SPI Driver Specification

        ## `spi_write` Function

        -   **Functional Requirements:** The function must write a given number of bytes to the SPI data register.
        -   **Error Handling:**
            -   If the `data` pointer is NULL, the function must immediately return `SPI_ERROR_NULL_POINTER` without accessing the pointer.
            -   If the `len` parameter is 0, the function must return `SPI_ERROR_INVALID_LENGTH`.
            -   The maximum value for the `len` parameter is 1024 bytes. Any attempt to write more than 1024 bytes should result in an `SPI_ERROR_INVALID_LENGTH` return code.
        -   **Performance:** The function must complete a 1024-byte transfer in under 50ms. 
        ```

*   **1.3. Update the Architectural Flow:**
    *   [ ] Acknowledge the need for a new node: `RequirementExtractionNode`.
    *   [ ] The new flow will be: `ProjectParserNode` -> `TestCandidateSelectionNode` -> **`RequirementExtractionNode`** -> `ContextualTestGeneratorNode` -> `FileWriterNode` -> `MakefileGeneratorNode`.

---

#### Phase 2: Core Feature Implementation (RAG for Specs)

*   **2.1. Enhance `ProjectParserNode`:**
    *   [ ] Modify `ProjectParserNode.exec` to also search for and load all `.md` and `.txt` files from the `specs/` directory.
    *   [ ] Store the content of these spec documents in the `shared` state (e.g., `shared['spec_documents']`).

*   **2.2. Implement `RequirementExtractionNode`:**
    *   [ ] Create the new `RequirementExtractionNode` class in `nodes.py`.
    *   [ ] **`prep`:** It should read the `shared['target_file']` (to know what we're testing) and `shared['spec_documents']`.
    *   [ ] **`exec`:** This is the core RAG logic.
        *   It should formulate a query based on the target, e.g., "What are the requirements for the `spi_write` function?".
        *   It will reuse the `get_embedding` utility to embed this query.
        *   It will embed all the spec documents (or chunks of them).
        *   It will use `cosine_similarity` to find the most relevant spec document/chunk.
        *   It should return the text of this most relevant requirement chunk.
    *   [ ] **`post`:** It should store the result in `shared['relevant_requirements']`.

*   **2.3. Upgrade `ContextualTestGeneratorNode`:**
    *   [ ] Modify its `prep` method to also pull `shared['relevant_requirements']`.
    *   [ ] **Crucially, upgrade the prompt** in its `exec` method to include a new section for the requirements. The prompt should now look like this:
        ```prompt
        You are an expert...

        ### Functional Requirements from Specification ###
        {the retrieved requirements text}

        ### Required Headers Context ###
        {the header file contents}
        
        ### Source Code to Test ###
        {the source code}

        Guidelines:
        1.  Generate tests that specifically verify each point from the "Functional Requirements" section above.
        2.  ... (rest of the guidelines) ...
        ```

*   **2.4. Update `flow.py`:**
    *   [ ] Import the new `RequirementExtractionNode`.
    *   [ ] Wire it into the `repo_testgen_flow` in the correct sequence.

---

#### Phase 3: Refinement and User Experience

*   **3.1. Handle "No Specs Found" Gracefully:**
    *   [ ] If `RequirementExtractionNode` finds no relevant specs, it should return a clear message like "No specific requirements found."
    *   [ ] The `ContextualTestGeneratorNode` prompt should be robust enough that it still works well even if the requirements section is empty or contains that message.

*   **3.2. Implement an Overwrite Guard:**
    *   [ ] In `FileWriterNode`, before writing the test file, check if the file already exists.
    *   [ ] If it does, prompt the user: `test_spi.c already exists. Overwrite? (y/n)`.

*   **3.3. Add a "Human-in-the-Loop" Review Step:**
    *   [ ] After `ContextualTestGeneratorNode` generates the test code, but before `FileWriterNode` runs, add a new `ReviewNode`.
    *   [ ] `ReviewNode` will print the generated code to the console and ask the user for approval: `Save this generated test file? (y/n)`. This allows the user to catch obvious LLM bugs before they are even written to disk.

---

#### Phase 4: Finalization & Documentation

*   **4.1. Full-Flow Testing:**
    *   [ ] Run the entire new flow with the `my_c_project` and the new `specs/spi_spec.md`.
    *   [ ] Verify that the generated `test_spi.c` now includes a test for the "max length of 1024 bytes" rule, which is only mentioned in the spec, not the code.

*   **4.2. Update `README.md`:**
    *   [ ] Add a section explaining the new spec-aware capability.
    *   [ ] Document the convention of placing specification documents in the `specs/` directory.

*   **4.3. Code Cleanup:**
    *   [ ] Review all new code for clarity, comments, and remove any temporary debugging prints.